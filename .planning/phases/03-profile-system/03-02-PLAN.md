---
phase: 03-profile-system
plan: 02
type: execute
wave: 2
depends_on:
  - 03-01
files_modified:
  - src/crawl4ai_mcp/profiles/default.yaml
  - src/crawl4ai_mcp/profiles/fast.yaml
  - src/crawl4ai_mcp/profiles/js_heavy.yaml
  - src/crawl4ai_mcp/profiles/stealth.yaml
  - src/crawl4ai_mcp/server.py
autonomous: true
requirements:
  - PROF-01
  - PROF-04

must_haves:
  truths:
    - "Four YAML profile files exist in src/crawl4ai_mcp/profiles/ (default, fast, js_heavy, stealth)"
    - "AppContext holds a profile_manager: ProfileManager field initialized in app_lifespan"
    - "crawl_url accepts a profile: str | None = None parameter"
    - "crawl_url with profile='fast' uses fast profile values (15s timeout, domcontentloaded) as base"
    - "crawl_url with profile='stealth' applies magic=True, simulate_user=True, delay_before_return_html=2.0"
    - "crawl_url per-call params (page_timeout, css_selector, etc.) override profile values when provided"
    - "_build_run_config is replaced by build_run_config from profiles.py — no duplicate config construction code"
    - "page_timeout conversion (seconds * 1000 = ms) happens before merge so profiles and per-call params use the same ms unit"
  artifacts:
    - path: "src/crawl4ai_mcp/profiles/default.yaml"
      provides: "Base defaults applied to every crawl"
      contains: "word_count_threshold: 10"
    - path: "src/crawl4ai_mcp/profiles/fast.yaml"
      provides: "Fast profile: domcontentloaded, 15s timeout, no JS waiting"
      contains: "page_timeout: 15000"
    - path: "src/crawl4ai_mcp/profiles/js_heavy.yaml"
      provides: "JS-heavy profile: networkidle, 90s timeout, full-page scroll"
      contains: "scan_full_page: true"
    - path: "src/crawl4ai_mcp/profiles/stealth.yaml"
      provides: "Stealth profile: magic, simulate_user, human-like delays"
      contains: "magic: true"
    - path: "src/crawl4ai_mcp/server.py"
      provides: "Updated server with ProfileManager in AppContext and profile param on crawl_url"
      exports: ["crawl_url", "AppContext", "app_lifespan"]
  key_links:
    - from: "src/crawl4ai_mcp/server.py"
      to: "src/crawl4ai_mcp/profiles.py"
      via: "import ProfileManager, build_run_config from profiles module"
      pattern: "from crawl4ai_mcp.profiles import"
    - from: "src/crawl4ai_mcp/server.py"
      to: "src/crawl4ai_mcp/profiles/"
      via: "ProfileManager loads *.yaml at startup via PROFILES_DIR"
      pattern: "ProfileManager\\("
    - from: "crawl_url tool"
      to: "build_run_config"
      via: "replaces _build_run_config call with build_run_config(app.profile_manager, profile, **per_call_kwargs)"
      pattern: "build_run_config\\(app\\.profile_manager"
---

<objective>
Ship four built-in YAML profile files and wire them into the server. Replace the inline `_build_run_config` helper with a call to `build_run_config` from `profiles.py`. Add a `profile` parameter to `crawl_url`.

Purpose: This is the user-visible deliverable of the profile system — after this plan, `crawl_url(url="...", profile="stealth")` works end-to-end.
Output: Four YAML files in `profiles/`, a leaner `server.py` with profile support wired into `AppContext` and `crawl_url`.
</objective>

<execution_context>
@/Users/brianpotter/.claude/get-shit-done/workflows/execute-plan.md
@/Users/brianpotter/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-profile-system/03-RESEARCH.md
@.planning/phases/03-profile-system/03-01-SUMMARY.md
@src/crawl4ai_mcp/server.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create four built-in YAML profile files</name>
  <files>
    src/crawl4ai_mcp/profiles/default.yaml
    src/crawl4ai_mcp/profiles/fast.yaml
    src/crawl4ai_mcp/profiles/js_heavy.yaml
    src/crawl4ai_mcp/profiles/stealth.yaml
  </files>
  <action>
Create the `src/crawl4ai_mcp/profiles/` directory and write four YAML files. All timeout values are in milliseconds (matching CrawlerRunConfig native units — document this with inline comments). Do NOT include `verbose` in any profile.

**src/crawl4ai_mcp/profiles/default.yaml** — base config applied to every crawl:
```yaml
# Default profile: applied as base layer for every crawl.
# All other profiles are merged on top of these values.
# page_timeout is in milliseconds (CrawlerRunConfig native unit).
wait_until: domcontentloaded
page_timeout: 60000      # 60 seconds
word_count_threshold: 10 # preserve current server.py behavior (CrawlerRunConfig default is 200)
```

**src/crawl4ai_mcp/profiles/fast.yaml** — minimal-JS, fast timeout:
```yaml
# Fast profile: optimized for static pages.
# Skips networkidle wait; short timeout; low word threshold.
# page_timeout is in milliseconds.
wait_until: domcontentloaded
page_timeout: 15000      # 15 seconds — fail fast on slow pages
word_count_threshold: 5  # retain short blocks on lightweight pages
```

**src/crawl4ai_mcp/profiles/js_heavy.yaml** — full JS rendering with page scroll:
```yaml
# JS-heavy profile: for pages with heavy client-side rendering.
# Waits for network idle; scrolls full page to trigger lazy loading.
# page_timeout is in milliseconds.
wait_until: networkidle
page_timeout: 90000       # 90 seconds — allow long JS execution
scan_full_page: true      # auto-scroll to trigger lazy-loaded content
scroll_delay: 0.5         # seconds between scroll steps
delay_before_return_html: 1.0  # wait 1s after networkidle before capturing
remove_overlay_elements: true  # dismiss cookie banners and modals
```

**src/crawl4ai_mcp/profiles/stealth.yaml** — anti-bot, human-like timing:
```yaml
# Stealth profile: anti-bot evasion using CrawlerRunConfig-level settings.
# BrowserConfig-level stealth (enable_stealth, user_agent_mode) is NOT supported
# in profiles — those are singleton settings requiring a browser restart.
# page_timeout is in milliseconds.
simulate_user: true           # random mouse movements and human-like delays
override_navigator: true      # mask headless browser navigator properties
magic: true                   # auto-handle overlays, popups, and anti-bot checks
delay_before_return_html: 2.0 # seconds to wait after page load before capture
mean_delay: 1.5               # mean seconds of human-like delay between actions
max_range: 2.0                # max variance in human delay (seconds)
wait_until: networkidle
page_timeout: 90000           # 90 seconds — stealth crawls take longer
```

Also create an empty `src/crawl4ai_mcp/profiles/__init__.py` if needed to prevent import confusion (profiles/ is a data directory, not a Python package — do NOT add __init__.py; it is a plain directory).
  </action>
  <verify>
`ls src/crawl4ai_mcp/profiles/` shows: default.yaml fast.yaml js_heavy.yaml stealth.yaml
`uv run python -c "import yaml; print(yaml.safe_load(open('src/crawl4ai_mcp/profiles/stealth.yaml')))"` prints dict with magic: True
  </verify>
  <done>Four YAML files exist with correct content. stealth.yaml has magic: true. fast.yaml has page_timeout: 15000. js_heavy.yaml has scan_full_page: true. default.yaml has word_count_threshold: 10.</done>
</task>

<task type="auto">
  <name>Task 2: Wire ProfileManager into server.py and add profile param to crawl_url</name>
  <files>src/crawl4ai_mcp/server.py</files>
  <action>
Make four targeted changes to `server.py`. Read the full file before editing to preserve all existing code.

**Change 1 — Add import:**
After the existing crawl4ai imports, add:
```python
from crawl4ai_mcp.profiles import ProfileManager, build_run_config
```

**Change 2 — Extend AppContext dataclass:**
Add `profile_manager: ProfileManager` field to AppContext:
```python
@dataclass
class AppContext:
    crawler: AsyncWebCrawler
    profile_manager: ProfileManager
```

**Change 3 — Initialize ProfileManager in app_lifespan:**
After `await crawler.start()`, instantiate ProfileManager and pass it to AppContext:
```python
profile_manager = ProfileManager()
logger.info("Loaded %d profile(s): %s", len(profile_manager.names), profile_manager.names)
# ...
yield AppContext(crawler=crawler, profile_manager=profile_manager)
```

**Change 4 — Replace _build_run_config call in crawl_url and add profile param:**
Add `profile: str | None = None` parameter to `crawl_url` (before `ctx`). Update the docstring to document it:
```
profile: Name of a built-in or custom crawl profile to use as the base
    configuration for this request. Per-call parameters take precedence
    over profile values. Available profiles: "fast", "js_heavy", "stealth".
    If None (default), only the "default" profile base is applied.
    Use list_profiles to see all available profiles and their settings.
```

Replace the call to `_build_run_config(...)` with:
```python
# Convert page_timeout from seconds (tool interface) to ms (CrawlerRunConfig)
per_call_kwargs = {
    "cache_mode": resolved_cache,
    "page_timeout": page_timeout * 1000,
}
if css_selector is not None:
    per_call_kwargs["css_selector"] = css_selector
if excluded_selector is not None:
    per_call_kwargs["excluded_selector"] = excluded_selector
if wait_for is not None:
    per_call_kwargs["wait_for"] = wait_for
if js_code is not None:
    per_call_kwargs["js_code"] = js_code
if user_agent is not None:
    per_call_kwargs["user_agent"] = user_agent
if word_count_threshold != 10:
    per_call_kwargs["word_count_threshold"] = word_count_threshold

app: AppContext = ctx.request_context.lifespan_context
run_cfg = build_run_config(app.profile_manager, profile, **per_call_kwargs)
```

NOTE: Only include optional params in per_call_kwargs if they are non-None (css_selector, excluded_selector, wait_for, js_code, user_agent) or non-default (word_count_threshold). This ensures profile values are not overridden by None/default values from the tool signature when the user didn't explicitly set them.

EXCEPTION: cache_mode and page_timeout are always included (they always have a resolved value from the tool call).

The existing `_build_run_config` helper function can be removed — it is now fully replaced by `build_run_config` from profiles.py. Remove it to avoid dead code.

Also update the `app: AppContext = ctx.request_context.lifespan_context` line — move it to BEFORE the `build_run_config` call (it's needed to get profile_manager).
  </action>
  <verify>
`uv run ruff check src/` — no errors
`uv run python -c "from crawl4ai_mcp.server import crawl_url, AppContext; print('ok')"` — prints "ok"
`uv run python -m crawl4ai_mcp.server 2>&1 1>/dev/null &` starts without error (Ctrl+C or kill after 3s)
  </verify>
  <done>
server.py imports build_run_config and ProfileManager from profiles.py. AppContext has profile_manager field. crawl_url has profile param. _build_run_config is removed. No ruff errors.
  </done>
</task>

</tasks>

<verification>
Full integration check:
```bash
uv run ruff check src/
uv run pytest tests/test_profiles.py -v
uv run python -c "
from crawl4ai_mcp.profiles import ProfileManager, build_run_config, PROFILES_DIR
pm = ProfileManager()
print('Profiles loaded:', pm.names)
assert 'fast' in pm.names
assert 'stealth' in pm.names
assert pm.get('fast')['page_timeout'] == 15000
assert pm.get('stealth')['magic'] == True
print('All assertions passed')
"
```
</verification>

<success_criteria>
- Four YAML files exist in src/crawl4ai_mcp/profiles/ with correct content
- server.py: AppContext has profile_manager field; crawl_url has profile param; _build_run_config is removed
- `uv run ruff check src/` passes clean
- `uv run pytest tests/test_profiles.py -v` all pass (tests written in 03-01)
- ProfileManager loads 4 profiles at startup (default + fast + js_heavy + stealth)
</success_criteria>

<output>
After completion, create `.planning/phases/03-profile-system/03-02-SUMMARY.md` following the summary template.
</output>
