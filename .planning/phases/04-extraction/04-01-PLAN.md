---
phase: 04-extraction
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/crawl4ai_mcp/server.py
  - tests/test_extraction.py
autonomous: true
requirements:
  - EXTR-01
  - EXTR-03
  - EXTR-04

must_haves:
  truths:
    - "Claude can call extract_structured with a JSON schema + instruction and receive typed JSON"
    - "extract_structured docstring prominently warns about LLM API cost"
    - "LLM API keys are resolved from server-side environment variables, never passed as tool parameters"
    - "crawl_url never triggers LLM extraction — extract_structured is a separate entry point"
    - "Missing API key env var returns a clear structured error before attempting the LLM call"
  artifacts:
    - path: "src/crawl4ai_mcp/server.py"
      provides: "extract_structured tool function with @mcp.tool() decorator"
      contains: "async def extract_structured"
    - path: "src/crawl4ai_mcp/server.py"
      provides: "_check_api_key helper for env var pre-validation"
      contains: "def _check_api_key"
    - path: "tests/test_extraction.py"
      provides: "Unit tests for _check_api_key and extract_structured parameter validation"
  key_links:
    - from: "src/crawl4ai_mcp/server.py extract_structured"
      to: "crawl4ai.LLMExtractionStrategy"
      via: "strategy construction with LLMConfig"
      pattern: "LLMExtractionStrategy.*llm_config.*LLMConfig"
    - from: "src/crawl4ai_mcp/server.py extract_structured"
      to: "AppContext.crawler"
      via: "ctx.request_context.lifespan_context"
      pattern: "ctx\\.request_context\\.lifespan_context"
---

<objective>
Add the `extract_structured` MCP tool for LLM-powered JSON extraction from web pages.

Purpose: Gives Claude the ability to extract structured data from any page using an LLM, with a clear cost warning, env-var-only key sourcing, and complete separation from `crawl_url` (EXTR-01, EXTR-03, EXTR-04).

Output: Working `extract_structured` tool in server.py, `_check_api_key` helper, unit tests for key validation logic.
</objective>

<execution_context>
@/Users/brianpotter/.claude/get-shit-done/workflows/execute-plan.md
@/Users/brianpotter/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-extraction/04-RESEARCH.md
@src/crawl4ai_mcp/server.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add _check_api_key helper and extract_structured tool to server.py</name>
  <files>src/crawl4ai_mcp/server.py</files>
  <action>
Add two new imports at the existing crawl4ai import line:
```python
from crawl4ai import LLMExtractionStrategy, LLMConfig
```

Add a module-level `PROVIDER_ENV_VARS` dict mapping provider prefixes to expected env var names:
```python
PROVIDER_ENV_VARS = {
    "openai": "OPENAI_API_KEY",
    "anthropic": "ANTHROPIC_API_KEY",
    "gemini": "GEMINI_API_KEY",
    "deepseek": "DEEPSEEK_API_KEY",
    "groq": "GROQ_API_KEY",
    "ollama": None,  # local, no key needed
}
```

Add `_check_api_key(provider: str) -> str | None` helper function (place after `_format_crawl_error`, before `_crawl_with_overrides`). It splits `provider` on "/" to get the prefix, looks up the expected env var, and returns a structured error string if the env var is not set. Returns `None` if the key exists or the provider is unknown/local (let litellm handle it).

Add `import os` at the top (standard library section).

Add the `extract_structured` tool function after `crawl_url`. Signature:
```python
@mcp.tool()
async def extract_structured(
    url: str,
    schema: dict,
    instruction: str,
    provider: str = "openai/gpt-4o-mini",
    css_selector: str | None = None,
    wait_for: str | None = None,
    js_code: str | None = None,
    page_timeout: int = 60,
    ctx: Context[ServerSession, AppContext] = None,
) -> str:
```

The docstring MUST start with a prominent cost warning:
```
"""Extract structured JSON from a page using an LLM.

WARNING: This tool calls an external LLM API and incurs token costs.
Each call may cost $0.01-$1+ depending on page size and model.
Use extract_css for cost-free deterministic extraction when possible.

Args:
    url: The URL to crawl and extract data from.
    schema: JSON Schema dict describing the desired output structure.
        Accepts both Pydantic .model_json_schema() output and simple
        {"type": "object", "properties": {...}} format.
    instruction: Natural language instruction for the LLM describing
        what to extract from the page content.
    provider: LLM provider and model in litellm format (default:
        "openai/gpt-4o-mini"). Examples: "anthropic/claude-sonnet-4-20250514",
        "gemini/gemini-2.0-flash". The API key is read from the
        corresponding environment variable (e.g. OPENAI_API_KEY) —
        never pass keys as parameters.
    css_selector: Restrict extraction scope to elements matching this
        CSS selector before passing content to the LLM.
    wait_for: Wait condition before extraction (CSS: "css:#el",
        JS: "js:() => expr").
    js_code: JavaScript to execute after page load, before extraction.
    page_timeout: Page load timeout in seconds (default 60).
"""
```

Implementation:
1. Call `_check_api_key(provider)` first. If it returns a string, return that error immediately.
2. Create `LLMConfig(provider=provider)` — key auto-resolved from env.
3. Create `LLMExtractionStrategy(llm_config=llm_config, schema=schema, extraction_type="schema", instruction=instruction, input_format="fit_markdown", verbose=False)`.
4. Construct `CrawlerRunConfig` directly (NOT via `build_run_config`) with `extraction_strategy=strategy, page_timeout=page_timeout * 1000, verbose=False`. Conditionally set `css_selector`, `wait_for`, `js_code` if not None.
5. Get `app: AppContext = ctx.request_context.lifespan_context`.
6. Call `result = await _crawl_with_overrides(app.crawler, url, run_cfg)`.
7. If `not result.success`, return `_format_crawl_error(url, result)`.
8. Check `result.extracted_content` — if None or empty, return a structured message: "Extraction returned no data\nURL: {url}\nThe LLM did not produce structured output. Check that the schema matches the page content."
9. Build usage report from `strategy.total_usage` (prompt_tokens, completion_tokens, total_tokens). NEVER call `strategy.show_usage()`.
10. Return `f"{result.extracted_content}\n\n--- LLM Usage ---\nProvider: {provider}\nPrompt tokens: {usage.prompt_tokens}\nCompletion tokens: {usage.completion_tokens}\nTotal tokens: {usage.total_tokens}"`.

Critical constraints:
- `verbose=False` on BOTH the strategy AND the CrawlerRunConfig — non-negotiable MCP transport safety.
- Do NOT pass `api_token` or `provider` directly to `LLMExtractionStrategy` — use `llm_config` exclusively.
- Do NOT call `strategy.show_usage()` — it uses `print()` which corrupts stdout.
- Do NOT route through `build_run_config` — extraction tools construct CrawlerRunConfig directly (research recommendation: Option A).
  </action>
  <verify>
Run `uv run ruff check src/crawl4ai_mcp/server.py` — no errors, no T201 (print) violations.
Run `python -c "from crawl4ai_mcp.server import extract_structured, _check_api_key, PROVIDER_ENV_VARS; print('imports ok')"` via `uv run` — confirms symbols exist and import.
  </verify>
  <done>
`extract_structured` tool exists in server.py with @mcp.tool() decorator, prominent cost warning in docstring, env-var-only key sourcing via `_check_api_key`, LLMConfig-based strategy construction, verbose=False on both strategy and config, and token usage reporting via `strategy.total_usage` (not `show_usage()`).
  </done>
</task>

<task type="auto">
  <name>Task 2: Add unit tests for _check_api_key and extract_structured registration</name>
  <files>tests/test_extraction.py</files>
  <action>
Create `tests/test_extraction.py` with the following test classes:

**TestCheckApiKey** — tests for the `_check_api_key` helper:
1. `test_openai_key_present` — set `OPENAI_API_KEY` in env (monkeypatch), call `_check_api_key("openai/gpt-4o-mini")`, assert returns `None`.
2. `test_openai_key_missing` — unset `OPENAI_API_KEY` (monkeypatch.delenv with raising=False), call `_check_api_key("openai/gpt-4o-mini")`, assert returns string containing "OPENAI_API_KEY" and "not set".
3. `test_anthropic_key_missing` — same pattern for "anthropic/claude-sonnet-4-20250514" expecting "ANTHROPIC_API_KEY".
4. `test_ollama_no_key_needed` — call `_check_api_key("ollama/llama3")`, assert returns `None` (ollama is local, no key).
5. `test_unknown_provider_passes` — call `_check_api_key("some-unknown/model")`, assert returns `None` (let litellm handle unknown providers).

**TestProviderEnvVars** — tests for the mapping:
1. `test_known_providers_mapped` — assert "openai", "anthropic", "gemini", "deepseek", "groq" are all keys in `PROVIDER_ENV_VARS`.
2. `test_ollama_maps_to_none` — assert `PROVIDER_ENV_VARS["ollama"]` is `None`.

**TestExtractStructuredRegistration** — tests that the tool is properly registered:
1. `test_tool_registered` — import `mcp` from `crawl4ai_mcp.server`, check that `extract_structured` appears in the server's tool list (use `mcp._tool_manager._tools` or call the tool listing method used in existing tests — match existing test patterns).
2. `test_docstring_has_cost_warning` — import `extract_structured` from `crawl4ai_mcp.server`, check that its `__doc__` contains "WARNING" and "cost" and "extract_css".

Import from `crawl4ai_mcp.server`: `_check_api_key`, `PROVIDER_ENV_VARS`, `extract_structured`.
Use `pytest` and `monkeypatch` fixture for env var manipulation.
  </action>
  <verify>
Run `uv run pytest tests/test_extraction.py -v` — all tests pass.
Run `uv run pytest` — all tests pass (including existing test_profiles.py tests, regression check).
  </verify>
  <done>
`tests/test_extraction.py` exists with tests covering `_check_api_key` (key present, key missing, ollama, unknown provider), `PROVIDER_ENV_VARS` mapping completeness, tool registration, and docstring cost warning. All tests pass. Existing tests still pass.
  </done>
</task>

</tasks>

<verification>
1. `uv run ruff check src/` — clean, no T201 print violations
2. `uv run pytest` — all tests pass (old + new)
3. `grep -c "WARNING" src/crawl4ai_mcp/server.py` — confirms cost warning in extract_structured docstring
4. `grep -c "show_usage" src/crawl4ai_mcp/server.py` — returns 0 (never called)
5. `grep -c "api_token" src/crawl4ai_mcp/server.py` — returns 0 (never passed as param)
6. `grep "verbose=False" src/crawl4ai_mcp/server.py` — appears in both LLMExtractionStrategy and CrawlerRunConfig construction
</verification>

<success_criteria>
- extract_structured tool exists and is registered as an MCP tool
- Tool docstring contains prominent cost warning mentioning extract_css as free alternative
- _check_api_key validates env vars before LLM call attempt
- No api_token parameter exposed in tool signature
- verbose=False on both strategy and config
- show_usage() never called anywhere
- All tests pass (new extraction tests + existing profile tests)
</success_criteria>

<output>
After completion, create `.planning/phases/04-extraction/04-01-SUMMARY.md`
</output>
