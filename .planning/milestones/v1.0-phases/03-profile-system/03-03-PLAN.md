---
phase: 03-profile-system
plan: 03
type: execute
wave: 3
depends_on:
  - 03-02
files_modified:
  - src/crawl4ai_mcp/server.py
autonomous: false
requirements:
  - PROF-02
  - PROF-03

must_haves:
  truths:
    - "list_profiles MCP tool exists and returns all loaded profiles with their key-value config"
    - "Adding a new YAML file to src/crawl4ai_mcp/profiles/ makes it visible in list_profiles output on next server start"
    - "list_profiles output is readable by Claude: each profile is clearly labeled with its name and settings"
    - "list_profiles distinguishes 'default' profile with a note explaining it is the base layer"
    - "Calling crawl_url with profile='fast' on a real URL returns clean markdown content (end-to-end smoke test)"
  artifacts:
    - path: "src/crawl4ai_mcp/server.py"
      provides: "list_profiles MCP tool registered with FastMCP"
      contains: "@mcp.tool()"
  key_links:
    - from: "list_profiles tool"
      to: "AppContext.profile_manager"
      via: "ctx.request_context.lifespan_context.profile_manager.all()"
      pattern: "profile_manager\\.all\\(\\)"
---

<objective>
Add the `list_profiles` MCP tool to `server.py` and run a manual smoke test confirming end-to-end profile functionality — a real URL crawl using profile="fast" and profile="stealth".

Purpose: Completes PROF-02 (user can see all profiles) and PROF-03 (custom profiles auto-discovered), and gives the user a human-verified confirmation that profiles work end-to-end before the phase is closed.
Output: `list_profiles` tool registered in server.py, smoke test result verified by user.
</objective>

<execution_context>
@/Users/brianpotter/.claude/get-shit-done/workflows/execute-plan.md
@/Users/brianpotter/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-profile-system/03-02-SUMMARY.md
@src/crawl4ai_mcp/server.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add list_profiles MCP tool to server.py</name>
  <files>src/crawl4ai_mcp/server.py</files>
  <action>
Add the `list_profiles` tool after the `ping` tool and before `crawl_url` in server.py. Read the current server.py first to find the right insertion point.

```python
@mcp.tool()
async def list_profiles(ctx: Context[ServerSession, AppContext]) -> str:
    """List all available crawl profiles and their configuration settings.

    Profiles provide named starting-point configurations for crawl_url.
    Per-call parameters always override profile values (merge order: default -> profile -> per-call).

    The 'default' profile is a special base layer automatically applied to every crawl,
    even when no profile is specified. All named profiles are merged on top of 'default'.

    To use a custom profile: create a YAML file in the profiles/ directory
    (e.g. profiles/my_profile.yaml) and pass profile='my_profile' to crawl_url.
    Custom profiles are picked up on next server restart.
    """
    app: AppContext = ctx.request_context.lifespan_context
    profiles = app.profile_manager.all()
    if not profiles:
        return "No profiles loaded. Check that src/crawl4ai_mcp/profiles/ directory exists."

    lines = []
    for name in sorted(profiles):
        cfg = profiles[name]
        if name == "default":
            lines.append(f"## {name} (base layer — applied to every crawl)")
        else:
            lines.append(f"## {name}")
        if not cfg:
            lines.append("  (no settings — inherits all defaults)")
        else:
            for k, v in sorted(cfg.items()):
                lines.append(f"  {k}: {v}")
        lines.append("")  # blank line between profiles

    return "\n".join(lines).rstrip()
```

Verify the tool is syntactically correct and ruff-clean before proceeding to the smoke test task.
  </action>
  <verify>
`uv run ruff check src/` — no errors
`uv run python -c "from crawl4ai_mcp.server import list_profiles; print('ok')"` — prints "ok"
  </verify>
  <done>list_profiles tool exists in server.py, has @mcp.tool() decorator, uses ctx.request_context.lifespan_context.profile_manager.all(), and passes ruff check.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: Smoke-test profile system end-to-end (human verify)</name>
  <action>Run the verification commands below and confirm results match expectations.</action>
  <what-built>
Complete Phase 3 profile system:
- ProfileManager loading YAML profiles from profiles/ directory
- build_run_config merge logic (default -> profile -> per-call)
- Four built-in profiles: default, fast, js_heavy, stealth
- crawl_url profile parameter
- list_profiles MCP tool

To test via Claude Code MCP (requires server restart to pick up changes):
1. Restart the MCP server (close/reopen Claude Code, or run the update command)
2. Call list_profiles — should show all four profiles with their settings
3. Call crawl_url with profile="fast" on https://webscraper.io/test-sites/tables
4. Call crawl_url with profile="stealth" on https://webscraper.io/test-sites/tables

To test directly (faster, no MCP restart needed):
```bash
uv run python -c "
from crawl4ai_mcp.profiles import ProfileManager, build_run_config
pm = ProfileManager()
print('Profiles:', pm.names)

# Test list_profiles output format
profiles = pm.all()
for name in sorted(profiles):
    print(f'  {name}: {list(profiles[name].keys())}')

# Test merge: fast profile with per-call page_timeout override
cfg = build_run_config(pm, 'fast', page_timeout=10000, cache_mode=__import__('crawl4ai').CacheMode.BYPASS)
print('fast+override page_timeout:', cfg.page_timeout, '(expect 10000)')
print('fast wait_until:', cfg.wait_until, '(expect domcontentloaded)')

# Test stealth merge
cfg2 = build_run_config(pm, 'stealth', cache_mode=__import__('crawl4ai').CacheMode.BYPASS)
print('stealth magic:', cfg2.magic, '(expect True)')
print('stealth verbose:', cfg2.verbose, '(expect False)')
print('All checks passed')
"
```

Custom profile test (PROF-03 — no code changes required):
```bash
cat > src/crawl4ai_mcp/profiles/test_custom.yaml << 'EOF'
wait_until: load
page_timeout: 5000
word_count_threshold: 3
EOF

uv run python -c "
from crawl4ai_mcp.profiles import ProfileManager
pm = ProfileManager()
print('custom profile loaded:', 'test_custom' in pm.names)
print('custom page_timeout:', pm.get('test_custom').get('page_timeout'))
"

# Clean up after test
rm src/crawl4ai_mcp/profiles/test_custom.yaml
```
  </what-built>
  <how-to-verify>
Run the direct test commands above. Expected output:
- Profiles list includes: default, fast, js_heavy, stealth
- fast profile page_timeout overridden to 10000 (per-call wins)
- fast wait_until is "domcontentloaded" (from profile)
- stealth magic is True
- stealth verbose is False (enforced)
- test_custom.yaml loaded without code changes (PROF-03 verified)

All assertions must pass before approving.
  </how-to-verify>
  <resume-signal>Type "approved" if all checks pass, or describe any failures</resume-signal>
</task>

</tasks>

<verification>
Final checks after checkpoint approval:
```bash
uv run ruff check src/
uv run pytest tests/test_profiles.py -v
uv run python -c "
from crawl4ai_mcp.profiles import ProfileManager, build_run_config
from crawl4ai import CacheMode
pm = ProfileManager()
assert set(pm.names) >= {'default', 'fast', 'js_heavy', 'stealth'}, f'Missing profiles: {pm.names}'
assert pm.get('fast')['page_timeout'] == 15000
assert pm.get('stealth')['magic'] == True
assert pm.get('js_heavy')['scan_full_page'] == True
assert pm.get('default')['word_count_threshold'] == 10
cfg = build_run_config(pm, 'stealth', cache_mode=CacheMode.BYPASS)
assert cfg.verbose == False
print('All Phase 3 verification checks passed')
"
```
</verification>

<success_criteria>
- list_profiles tool is in server.py with @mcp.tool() decorator and correct AppContext access
- list_profiles output labels 'default' as the base layer and shows all settings for each profile
- Human checkpoint approved: merge order verified, stealth magic=True verified, verbose=False enforced, custom YAML auto-discovered
- `uv run pytest tests/test_profiles.py -v` all pass
- `uv run ruff check src/` clean
</success_criteria>

<output>
After completion, create `.planning/phases/03-profile-system/03-03-SUMMARY.md` following the summary template.
</output>
