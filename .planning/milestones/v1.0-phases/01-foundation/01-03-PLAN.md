---
phase: 01-foundation
plan: 3
type: execute
wave: 3
depends_on:
  - "01-01"
  - "01-02"
files_modified:
  - README.md
autonomous: true
requirements:
  - INFRA-01
  - INFRA-05

must_haves:
  truths:
    - "README contains a copy-pasteable claude mcp add-json command with the correct absolute path"
    - "README contains the raw JSON config block that users can add to ~/.claude.json manually"
    - "A user following only the README can register the server and connect Claude Code to it"
    - "The server is registered as a global user-scoped MCP server in Claude Code"
    - "claude mcp list shows crawl4ai in the registered server list"
  artifacts:
    - path: "README.md"
      provides: "Installation steps, registration command, JSON config snippet, verification steps"
      contains: "claude mcp add-json --scope user crawl4ai"
  key_links:
    - from: "README.md registration command"
      to: "src/crawl4ai_mcp/server.py"
      via: "--directory /absolute/path pointing to the project root, python -m crawl4ai_mcp.server"
      pattern: "python.*-m.*crawl4ai_mcp\\.server"
    - from: "claude mcp add-json"
      to: "uv run --directory"
      via: "args array in JSON config — must include --directory with absolute path so uv finds the venv"
      pattern: "--directory"
---

<objective>
Write README.md with exact, copy-pasteable registration instructions and register the server as a global Claude Code MCP server. After this plan, any developer can clone the repo, follow the README, and have a working crawl4ai MCP server in Claude Code.

Purpose: INFRA-05 requires documentation that is immediately actionable — not a reference, but a step-by-step runbook. The registration also validates the full stack end-to-end: if Claude Code can connect and list tools, Phase 1 is complete.
Output: README.md with prerequisites, installation, registration command, and verification steps. Server registered and visible in `claude mcp list`.
</objective>

<execution_context>
@/Users/brianpotter/.claude/get-shit-done/workflows/execute-plan.md
@/Users/brianpotter/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-foundation/01-RESEARCH.md
@.planning/phases/01-foundation/01-01-SUMMARY.md
@.planning/phases/01-foundation/01-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Write README.md with installation and registration instructions</name>
  <files>README.md</files>
  <action>
Write /Users/brianpotter/ai_tools/crawl4ai_mcp/README.md. The content must be immediately actionable — a developer with Python and uv installed should be able to register the server in under 5 minutes.

The absolute path used in all code blocks must be the REAL path to this project: `/Users/brianpotter/ai_tools/crawl4ai_mcp`. Do not use a placeholder like `/path/to/project`.

Write this content:

```markdown
# crawl4ai MCP Server

A local MCP server that gives Claude Code the ability to crawl web pages and extract content using [crawl4ai](https://docs.crawl4ai.com). Claude can crawl any URL, extract structured data, and orchestrate multi-page crawls — all through MCP tool calls, without leaving the coding session.

## Prerequisites

- Python 3.12+
- [uv](https://docs.astral.sh/uv/getting-started/installation/) — Python package manager
- Claude Code CLI (`claude`)

## Installation

```bash
# Clone the repository
git clone <repo-url> /Users/brianpotter/ai_tools/crawl4ai_mcp
cd /Users/brianpotter/ai_tools/crawl4ai_mcp

# Install dependencies (uv manages the virtualenv automatically)
uv sync

# Install Playwright browser (required by crawl4ai — downloads Chromium)
uv run crawl4ai-setup

# Verify the installation
uv run crawl4ai-doctor
```

## Register with Claude Code

Register the server as a global MCP server so it is available in all Claude Code sessions:

```bash
claude mcp add-json --scope user crawl4ai '{
  "type": "stdio",
  "command": "uv",
  "args": [
    "run",
    "--directory",
    "/Users/brianpotter/ai_tools/crawl4ai_mcp",
    "python",
    "-m",
    "crawl4ai_mcp.server"
  ]
}'
```

### Verify Registration

```bash
# List registered MCP servers — crawl4ai should appear
claude mcp list
```

### Manual Registration (Alternative)

If you prefer to edit `~/.claude.json` directly, add the following under `mcpServers`:

```json
{
  "crawl4ai": {
    "type": "stdio",
    "command": "uv",
    "args": [
      "run",
      "--directory",
      "/Users/brianpotter/ai_tools/crawl4ai_mcp",
      "python",
      "-m",
      "crawl4ai_mcp.server"
    ]
  }
}
```

## Available Tools

| Tool | Description |
|------|-------------|
| `ping` | Verify the server is running and the browser is ready |

More tools are added in Phase 2 (crawl), Phase 3 (profiles), Phase 4 (extraction), and Phase 5 (multi-page crawl).

## How It Works

The server uses [FastMCP](https://github.com/modelcontextprotocol/python-sdk) (stdio transport) and manages a single `AsyncWebCrawler` (Chromium via Playwright) that starts at server boot and is reused across all tool calls. This means:

- No per-request browser startup cost
- No orphaned browser processes after shutdown
- All server logging goes to stderr — stdout carries only MCP protocol frames

## Development

```bash
# Run the server directly (for debugging — MCP Inspector recommended for interactive testing)
uv run python -m crawl4ai_mcp.server

# Lint
uv run ruff check src/

# Test
uv run pytest
```

## Troubleshooting

**Tools don't appear in Claude Code**
Check that the `--directory` path in the registration command matches the actual project location. `uv run` without `--directory` looks for the virtualenv in Claude Code's working directory, not this project.

**Server disconnects immediately**
Any output to stdout (from a `print()` call or `verbose=True` in crawl4ai config) corrupts the MCP stdio transport. Check stderr for the actual error: `uv run python -m crawl4ai_mcp.server 2>&1 1>/dev/null`.

**Chromium fails to start**
Run `uv run crawl4ai-doctor` to diagnose. If Playwright browsers are missing, run `uv run crawl4ai-setup` again.
```

Note: The triple-backtick code fences in the markdown above are real fences for the README — write them exactly as shown including the nested fences (the bash/json/markdown blocks inside the README content).
  </action>
  <verify>
```bash
# README exists and contains required content
grep -n "claude mcp add-json --scope user crawl4ai" /Users/brianpotter/ai_tools/crawl4ai_mcp/README.md && echo "registration command found"
grep -n "\-\-directory" /Users/brianpotter/ai_tools/crawl4ai_mcp/README.md && echo "--directory flag found"
grep -n "python.*-m.*crawl4ai_mcp.server" /Users/brianpotter/ai_tools/crawl4ai_mcp/README.md && echo "module invocation found"
grep -n "/Users/brianpotter/ai_tools/crawl4ai_mcp" /Users/brianpotter/ai_tools/crawl4ai_mcp/README.md && echo "absolute path found"
grep -n "mcpServers" /Users/brianpotter/ai_tools/crawl4ai_mcp/README.md && echo "manual JSON config found"
```

All five checks must produce output.
  </verify>
  <done>README.md contains: one-line registration command with --scope user and --directory /Users/brianpotter/ai_tools/crawl4ai_mcp, a raw JSON config block for manual ~/.claude.json editing, troubleshooting section, and tool table.</done>
</task>

<task type="auto">
  <name>Task 2: Register the server with Claude Code and verify connection</name>
  <files></files>
  <action>
Register the server as a global Claude Code MCP server and verify it appears in the server list.

```bash
# Register the server
claude mcp add-json --scope user crawl4ai '{
  "type": "stdio",
  "command": "uv",
  "args": [
    "run",
    "--directory",
    "/Users/brianpotter/ai_tools/crawl4ai_mcp",
    "python",
    "-m",
    "crawl4ai_mcp.server"
  ]
}'

# Verify it is listed
claude mcp list
```

If `claude mcp add-json` fails because `crawl4ai` is already registered (from a prior attempt), remove the existing entry first and re-add:

```bash
claude mcp remove crawl4ai --scope user 2>/dev/null || true
claude mcp add-json --scope user crawl4ai '{
  "type": "stdio",
  "command": "uv",
  "args": [
    "run",
    "--directory",
    "/Users/brianpotter/ai_tools/crawl4ai_mcp",
    "python",
    "-m",
    "crawl4ai_mcp.server"
  ]
}'
claude mcp list
```

If `claude mcp list` shows `crawl4ai` in the output, the registration is complete.

**Verify the scope flag is correct:** Run `claude mcp --help` to confirm whether the flag is `--scope user` or `--scope global`. The research notes `--scope user` with HIGH confidence, but the open question in the research doc flags that `--scope global` may be an alias. Use whichever the help output shows as valid for user-scoped (persisted in `~/.claude.json`) registration. Update the README if the actual flag differs.
  </action>
  <verify>
```bash
claude mcp list | grep crawl4ai && echo "PASS: crawl4ai server registered"
```

The output must show `crawl4ai` in the list. If `claude mcp list` is not available, check `~/.claude.json` directly:

```bash
cat ~/.claude.json | python3 -c "import sys,json; cfg=json.load(sys.stdin); servers=cfg.get('mcpServers',{}); print('registered servers:', list(servers.keys())); assert 'crawl4ai' in servers, 'crawl4ai not found in ~/.claude.json'; print('PASS')"
```
  </verify>
  <done>crawl4ai appears in `claude mcp list` output (or in ~/.claude.json mcpServers), with command=uv and args containing --directory and the absolute project path.</done>
</task>

</tasks>

<verification>
Final verification for Plan 01-03 (Phase 1 complete):

```bash
# 1. README contains all required content
grep -c "claude mcp add-json --scope user crawl4ai" /Users/brianpotter/ai_tools/crawl4ai_mcp/README.md
grep -c "mcpServers" /Users/brianpotter/ai_tools/crawl4ai_mcp/README.md
grep -c "/Users/brianpotter/ai_tools/crawl4ai_mcp" /Users/brianpotter/ai_tools/crawl4ai_mcp/README.md

# 2. Server is registered
claude mcp list | grep crawl4ai

# 3. Full stdout smoke test with real browser (confirms end-to-end)
echo '{"jsonrpc":"2.0","id":1,"method":"initialize","params":{"protocolVersion":"2024-11-05","capabilities":{},"clientInfo":{"name":"test","version":"1.0"}}}' \
  | timeout 15 uv run --directory /Users/brianpotter/ai_tools/crawl4ai_mcp python -m crawl4ai_mcp.server 2>/dev/null \
  | python3 -c "import sys,json; data=sys.stdin.read(); lines=[l for l in data.split('\n') if l.strip()]; [json.loads(l) for l in lines]; print('PASS: Phase 1 complete — server returns valid JSON-RPC on stdout')"
```
</verification>

<success_criteria>
- README.md exists with copy-pasteable `claude mcp add-json` command containing --scope user, --directory, and absolute path
- README.md contains a raw JSON config block for manual ~/.claude.json editing
- `claude mcp list` shows crawl4ai in the registered servers
- The registration command uses the correct absolute path /Users/brianpotter/ai_tools/crawl4ai_mcp
- Stdout smoke test invoked via `uv run --directory` (as Claude Code would invoke it) passes
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-03-SUMMARY.md` documenting:
- README sections written and their purposes
- Exact registration command used (note if --scope flag differed from --scope user)
- Output of `claude mcp list` confirming registration
- Result of final stdout smoke test using the --directory invocation form
- Any deviations from the plan and why
- Phase 1 complete: confirm all 5 success criteria from ROADMAP.md are met
</output>
